{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('./data/BTCUSDT_1m.csv')\n",
    "\n",
    "# Display summary statistics\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "df = df.sort_values(by='open_time', ascending=True).reset_index(drop=True)\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get memory usage of the dataframe\n",
    "memory_usage = df.memory_usage(deep=True)\n",
    "\n",
    "# Convert to MB for better readability\n",
    "memory_usage_mb = memory_usage.sum() / 1024 / 1024\n",
    "\n",
    "print(\"\\nMemory usage breakdown by column (bytes):\")\n",
    "for column, usage in memory_usage.items():\n",
    "    print(f\"{column}: {usage:,} bytes\")\n",
    "    \n",
    "print(f\"\\nTotal memory usage: {memory_usage_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping old column names to new ones with '1m_' prefix\n",
    "rename_dict = {\n",
    "    'open_time': '1m_open_time',\n",
    "    'close_time': '1m_close_time', \n",
    "    'open_px': '1m_open_px',\n",
    "    'high_px': '1m_high_px',\n",
    "    'low_px': '1m_low_px',\n",
    "    'close_px': '1m_close_px',\n",
    "    'number_of_trades': '1m_number_of_trades',\n",
    "    'base_asset_volume': '1m_base_asset_volume',\n",
    "    'quote_asset_volume': '1m_quote_asset_volume',\n",
    "    'taker_buy_base_asset_volume': '1m_taker_buy_base_asset_volume',\n",
    "    'taker_buy_quote_asset_volume': '1m_taker_buy_quote_asset_volume'\n",
    "}\n",
    "\n",
    "# Rename the columns\n",
    "df = df.rename(columns=rename_dict)\n",
    "\n",
    "# Display the new column names\n",
    "print(\"New column names:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['1m_open_time', '1m_close_time', '1m_open_px', '1m_high_px', '1m_low_px', '1m_close_px']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-minute aggregations\n",
    "# First create a group index (0-4) that repeats every 5 rows\n",
    "df['group_idx'] = df.index % 5\n",
    "\n",
    "# Create is_5m_closed column - True for last entry in each group\n",
    "df['is_5m_closed'] = df['group_idx'] == 4\n",
    "\n",
    "# Group by integer division of index to get 5-minute groups\n",
    "groups = df.groupby(df.index // 5)\n",
    "\n",
    "# Create 5m columns - using cummax/cummin within groups for high/low prices\n",
    "df['5m_open_time'] = groups['1m_open_time'].transform('first')\n",
    "df['5m_close_time'] = groups['1m_close_time'].transform('last') \n",
    "df['5m_open_px'] = groups['1m_open_px'].transform('first')\n",
    "df['5m_high_px'] = groups['1m_high_px'].transform('cummax')\n",
    "df['5m_low_px'] = groups['1m_low_px'].transform('cummin')\n",
    "df['5m_close_px'] = df['1m_close_px']\n",
    "\n",
    "# Drop temporary grouping column\n",
    "df = df.drop('group_idx', axis=1)\n",
    "\n",
    "# Display first few rows to verify\n",
    "df[['5m_open_time', '5m_close_time', '5m_open_px', '5m_high_px', '5m_low_px', '5m_close_px', 'is_5m_closed']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 15-minute aggregations from 1m data\n",
    "df['group_idx'] = df.index % 15\n",
    "\n",
    "# Create is_15m_closed column - True for last entry in each group\n",
    "df['is_15m_closed'] = df['group_idx'] == 14\n",
    "\n",
    "# Group by integer division of index to get 5-minute groups\n",
    "groups = df.groupby(df.index // 15)\n",
    "\n",
    "# Create 15m columns - using cummax/cummin within groups for high/low prices\n",
    "df['15m_open_time'] = groups['1m_open_time'].transform('first')\n",
    "df['15m_close_time'] = groups['1m_close_time'].transform('last') \n",
    "df['15m_open_px'] = groups['1m_open_px'].transform('first')\n",
    "df['15m_high_px'] = groups['1m_high_px'].transform('cummax')\n",
    "df['15m_low_px'] = groups['1m_low_px'].transform('cummin')\n",
    "df['15m_close_px'] = df['1m_close_px']\n",
    "\n",
    "# Drop temporary grouping column\n",
    "df = df.drop('group_idx', axis=1)\n",
    "\n",
    "# Display first few rows to verify\n",
    "df[['15m_open_time', '15m_close_time', '15m_open_px', '15m_high_px', '15m_low_px', '15m_close_px', 'is_15m_closed']].head(15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1-hour aggregations from 1m data\n",
    "df['group_idx'] = df.index % 60\n",
    "\n",
    "# Create is_5m_closed column - True for last entry in each group\n",
    "df['is_1h_closed'] = df['group_idx'] == 59\n",
    "\n",
    "# Group by integer division of index to get 5-minute groups\n",
    "groups = df.groupby(df.index // 60)\n",
    "\n",
    "# Create 5m columns - using cummax/cummin within groups for high/low prices\n",
    "df['1h_open_time'] = groups['1m_open_time'].transform('first')\n",
    "df['1h_close_time'] = groups['1m_close_time'].transform('last') \n",
    "df['1h_open_px'] = groups['1m_open_px'].transform('first')\n",
    "df['1h_high_px'] = groups['1m_high_px'].transform('cummax')\n",
    "df['1h_low_px'] = groups['1m_low_px'].transform('cummin')\n",
    "df['1h_close_px'] = df['1m_close_px']\n",
    "\n",
    "# Drop temporary grouping column\n",
    "df = df.drop('group_idx', axis=1)\n",
    "\n",
    "# Display first few rows to verify\n",
    "df[['1h_open_time', '1h_close_time', '1h_open_px', '1h_high_px', '1h_low_px', '1h_close_px', 'is_1h_closed']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 4-hour aggregations from 1m data\n",
    "df['group_idx'] = df.index % 240\n",
    "\n",
    "# Create is_4h_closed column - True for last entry in each group\n",
    "df['is_4h_closed'] = df['group_idx'] == 239\n",
    "\n",
    "groups = df.groupby(df.index // 240)\n",
    "\n",
    "df['4h_open_time'] = groups['1m_open_time'].transform('first')\n",
    "df['4h_close_time'] = groups['1m_close_time'].transform('last') \n",
    "df['4h_open_px'] = groups['1m_open_px'].transform('first')\n",
    "df['4h_high_px'] = groups['1m_high_px'].transform('cummax')\n",
    "df['4h_low_px'] = groups['1m_low_px'].transform('cummin')\n",
    "df['4h_close_px'] = df['1m_close_px']\n",
    "\n",
    "# Drop temporary grouping column\n",
    "df = df.drop('group_idx', axis=1)\n",
    "\n",
    "# Display first few rows to verify\n",
    "df[['4h_open_time', '4h_close_time', '4h_open_px', '4h_high_px', '4h_low_px', '4h_close_px', 'is_4h_closed']].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1-day aggregations from 1m data\n",
    "df['group_idx'] = df.index % 1440\n",
    "\n",
    "# Create is_1d_closed column - True for last entry in each group\n",
    "df['is_1d_closed'] = df['group_idx'] == 1439\n",
    "\n",
    "groups = df.groupby(df.index // 1440)\n",
    "\n",
    "df['1d_open_time'] = groups['1m_open_time'].transform('first')\n",
    "df['1d_close_time'] = groups['1m_close_time'].transform('last') \n",
    "df['1d_open_px'] = groups['1m_open_px'].transform('first')\n",
    "df['1d_high_px'] = groups['1m_high_px'].transform('cummax')\n",
    "df['1d_low_px'] = groups['1m_low_px'].transform('cummin')\n",
    "df['1d_close_px'] = df['1m_close_px']\n",
    "\n",
    "df = df.drop('group_idx', axis=1)\n",
    "\n",
    "df[['1d_open_time', '1d_close_time', '1d_open_px', '1d_high_px', '1d_low_px', '1d_close_px', 'is_1d_closed']].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy 1, Buy on 0:00, Sell on 12:00\n",
    "df[\"signal_1\"] = 0\n",
    "df.loc[df[\"1m_open_time\"] % 86400000 == 0, \"signal_1\"] = 1\n",
    "df.loc[df[\"1m_open_time\"] % 86400000 == 43200000, \"signal_1\"] = -1\n",
    "# Vectorized calculation of asset positions\n",
    "df[\"asset_1_usdt\"] = 1000\n",
    "df[\"asset_1_btc\"] = 0\n",
    "\n",
    "df[\"signal_1\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = len(df)\n",
    "usdt_list = [0] * n\n",
    "btc_list = [0] * n\n",
    "portfolio_list = [0] * n\n",
    "\n",
    "usdt_list[0] = 1000\n",
    "btc_list[0] = 0\n",
    "portfolio_list[0] = 1000\n",
    "\n",
    "\n",
    "n_trade_usdt = 500\n",
    "\n",
    "for i in range(len(df) - 1):\n",
    "    n_btc = btc_list[i]\n",
    "    n_usdt = usdt_list[i]\n",
    "    price = df[\"1m_close_px\"].iloc[i]\n",
    "    signal = df[\"signal_1\"].iloc[i]\n",
    "\n",
    "    if signal == 1:\n",
    "        n_usdt = n_usdt - n_trade_usdt\n",
    "        n_btc = n_btc + n_trade_usdt / price\n",
    "    elif signal == -1:\n",
    "        n_usdt = n_usdt + n_trade_usdt\n",
    "        n_btc = n_btc - n_trade_usdt / price\n",
    "    elif signal == 0:\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Invalid signal\")\n",
    "    \n",
    "    usdt_list[i + 1] = n_usdt\n",
    "    btc_list[i + 1] = n_btc\n",
    "    \n",
    "df[\"btc_1\"] = btc_list\n",
    "df[\"usdt_1\"] = usdt_list\n",
    "df[\"portfolio_1_open_px\"] = df[\"btc_1\"] * df[\"1m_open_px\"] + df[\"usdt_1\"]\n",
    "df[\"portfolio_1_high_px\"] = df[\"btc_1\"] * df[\"1m_high_px\"] + df[\"usdt_1\"]\n",
    "df[\"portfolio_1_low_px\"] = df[\"btc_1\"] * df[\"1m_low_px\"] + df[\"usdt_1\"]\n",
    "df[\"portfolio_1_close_px\"] = df[\"btc_1\"] * df[\"1m_close_px\"] + df[\"usdt_1\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 1-day aggregations from 1m data\n",
    "df['group_idx'] = df.index % 1440\n",
    "\n",
    "groups = df.groupby(df.index // 1440)\n",
    "\n",
    "# Aggregate portfolio values to daily level\n",
    "df['1d_portfolio_1_open'] = groups['portfolio_1_open_px'].transform('first')\n",
    "df['1d_portfolio_1_high'] = groups['portfolio_1_high_px'].transform('max')\n",
    "df['1d_portfolio_1_low'] = groups['portfolio_1_low_px'].transform('min')\n",
    "df['1d_portfolio_1_close'] = groups['portfolio_1_close_px'].transform('last')\n",
    "\n",
    "df = df.drop('group_idx', axis=1)\n",
    "\n",
    "df[['1d_portfolio_1_open', '1d_portfolio_1_high', '1d_portfolio_1_low', '1d_portfolio_1_close']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select January 2022 data (first month in the dataset based on context)\n",
    "start_time = 1640995200000  # Jan 1, 2022\n",
    "end_time = 1643673600000   # Jan 31, 2022\n",
    "df_portfolio = df[['1d_open_time', '1d_close_time', '1d_portfolio_1_open', '1d_portfolio_1_high', '1d_portfolio_1_low', '1d_portfolio_1_close', 'is_1d_closed']]\n",
    "\n",
    "df_portfolio = df_portfolio[df_portfolio['is_1d_closed'] == True]\n",
    "df_portfolio\n",
    "# Filter data for January\n",
    "jan_portfolio = df_portfolio[(df_portfolio['1d_open_time'] >= start_time) & (df_portfolio['1d_open_time'] < end_time)]\n",
    "# \n",
    "# \n",
    "# # Plot candlestick chart\n",
    "import mplfinance as mpf\n",
    "\n",
    "# Create a pandas DataFrame with proper datetime index\n",
    "jan_portfolio_df = jan_portfolio.copy()\n",
    "jan_portfolio_df.index = pd.date_range(start='2022-01-01', periods=len(jan_portfolio_df), freq='D')\n",
    "jan_portfolio_df = jan_portfolio_df.rename(columns={\n",
    "    '1d_open_time': 'Date',\n",
    "    '1d_portfolio_1_open': 'Open',\n",
    "    '1d_portfolio_1_high': 'High',\n",
    "    '1d_portfolio_1_low': 'Low',\n",
    "    '1d_portfolio_1_close': 'Close'\n",
    "})\n",
    "\n",
    "# Plot using mplfinance\n",
    "mpf.plot(jan_portfolio_df, \n",
    "         type='candle',\n",
    "         title='Portfolio Performance - January 2022',\n",
    "         ylabel='Portfolio Value (USDT)',\n",
    "         volume=False,\n",
    "         style='yahoo')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select January 2022 data (first month in the dataset based on context)\n",
    "start_time = 1640995200000  # Jan 1, 2022\n",
    "end_time = 1643673600000   # Jan 31, 2022\n",
    "df_btc = df[['1d_open_time', '1d_close_time', '1d_open_px', '1d_high_px', '1d_low_px', '1d_close_px', 'is_1d_closed']]\n",
    "\n",
    "df_btc = df_btc[df_btc['is_1d_closed'] == True]\n",
    "# Filter data for January\n",
    "jan_btc = df_btc[(df_btc['1d_open_time'] >= start_time) & (df_portfolio['1d_open_time'] < end_time)]\n",
    "# \n",
    "# \n",
    "# # Plot candlestick chart\n",
    "import mplfinance as mpf\n",
    "\n",
    "# Create a pandas DataFrame with proper datetime index\n",
    "jan_btc_df = jan_btc.copy()\n",
    "jan_btc_df.index = pd.date_range(start='2022-01-01', periods=len(jan_btc_df), freq='D')\n",
    "jan_btc_df = jan_btc_df.rename(columns={\n",
    "    '1d_open_time': 'Date',\n",
    "    '1d_open_px': 'Open',\n",
    "    '1d_high_px': 'High',\n",
    "    '1d_low_px': 'Low',\n",
    "    '1d_close_px': 'Close'\n",
    "})\n",
    "jan_btc_df.head()\n",
    "\n",
    "# Plot using mplfinance\n",
    "mpf.plot(jan_btc_df, \n",
    "         type='candle',\n",
    "         title='BTC Performance - January 2022',\n",
    "         ylabel='BTC Value (USDT)',\n",
    "         volume=False,\n",
    "         style='yahoo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get January 2022 start and end timestamps\n",
    "jan_2022_start = pd.Timestamp('2022-01-01').timestamp() * 1000  # Convert to milliseconds\n",
    "jan_2022_end = pd.Timestamp('2022-02-01').timestamp() * 1000  # Convert to milliseconds\n",
    "\n",
    "\n",
    "# Filter data for January 2022\n",
    "jan_df = df[(df['1m_open_time'] >= jan_2022_start) & (df['1m_open_time'] < jan_2022_end)]\n",
    "# Calculate monthly simple return using first and last close prices\n",
    "first_close = jan_df['portfolio_1_close_px'].iloc[0]\n",
    "last_close = jan_df['portfolio_1_close_px'].iloc[-1]\n",
    "simple_return = (last_close - first_close) / first_close\n",
    "# Calculate monthly volatility using daily returns\n",
    "minutely_returns = jan_df['portfolio_1_close_px'].pct_change()\n",
    "monthly_volatility = minutely_returns.std() * np.sqrt(len(jan_df))  # Monthly volatility\n",
    "# Calculate maximum drawdown\n",
    "cumulative_max = jan_df['portfolio_1_close_px'].expanding().max()\n",
    "drawdowns = (jan_df['portfolio_1_close_px'] - cumulative_max) / cumulative_max\n",
    "max_drawdown = drawdowns.min()\n",
    "\n",
    "print(f\"January 2022 Portfolio Statistics:\")\n",
    "print(f\"N Sample: {len(jan_df)}\")\n",
    "print(f\"N Trade: {jan_df['signal_1'].abs().sum()}\")\n",
    "print(f\"Simple Return: {simple_return:.2%}\")\n",
    "print(f\"Monthly Volatility: {monthly_volatility:.2%}\")\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get January 2022 start and end timestamps\n",
    "jan_2022_start = pd.Timestamp('2022-01-01').timestamp() * 1000  # Convert to milliseconds\n",
    "jan_2022_end = pd.Timestamp('2022-02-01').timestamp() * 1000  # Convert to milliseconds\n",
    "\n",
    "\n",
    "# Filter data for January 2022\n",
    "jan_df = df[(df['1m_open_time'] >= jan_2022_start) & (df['1m_open_time'] < jan_2022_end)]\n",
    "# Calculate monthly simple return using first and last close prices\n",
    "first_close = jan_df['1m_close_px'].iloc[0]\n",
    "last_close = jan_df['1m_close_px'].iloc[-1]\n",
    "simple_return = (last_close - first_close) / first_close\n",
    "# Calculate monthly volatility using daily returns\n",
    "minutely_returns = jan_df['1m_close_px'].pct_change()\n",
    "monthly_volatility = minutely_returns.std() * np.sqrt(len(jan_df))  # Monthly volatility\n",
    "# Calculate maximum drawdown\n",
    "cumulative_max = jan_df['1m_close_px'].expanding().max()\n",
    "drawdowns = (jan_df['1m_close_px'] - cumulative_max) / cumulative_max\n",
    "max_drawdown = drawdowns.min()\n",
    "\n",
    "print(f\"January 2022 BTC Statistics:\")\n",
    "print(f\"N Sample: {len(jan_df)}\")\n",
    "print(f\"Simple Return: {simple_return:.2%}\")\n",
    "print(f\"Monthly Volatility: {monthly_volatility:.2%}\")\n",
    "print(f\"Maximum Drawdown: {max_drawdown:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(df: pd.DataFrame, year: int, month: int) -> dict:\n",
    "    # Validate month\n",
    "    if not (1 <= month <= 12):\n",
    "        raise ValueError(f\"Invalid month: {month}. Month must be between 1 and 12.\")\n",
    "\n",
    "    # Check required columns\n",
    "    required_columns = ['Date', 'Close', 'N_Trades']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        raise KeyError(f\"Missing required column(s): {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Get start and end timestamps in milliseconds\n",
    "    start = pd.Timestamp(f\"{year}-{month:02d}-01\").timestamp() * 1000\n",
    "    if month == 12:\n",
    "        end = pd.Timestamp(f\"{year + 1}-01-01\").timestamp() * 1000\n",
    "    else:\n",
    "        end = pd.Timestamp(f\"{year}-{month + 1:02d}-01\").timestamp() * 1000\n",
    "\n",
    "    # Filter data for the specified month\n",
    "    monthly_df = df[(df['Date'] >= start) & (df['Date'] < end)]\n",
    "\n",
    "    if monthly_df.empty:\n",
    "        return {\n",
    "            \"n_sample\": 0,\n",
    "            \"n_trade\": 0,\n",
    "            \"monthly_return\": 0.0,\n",
    "            \"monthly_volatility\": 0.0,\n",
    "            \"monthly_mdd\": 0.0\n",
    "        }\n",
    "\n",
    "    # Calculate simple return\n",
    "    first_close = monthly_df['Close'].iloc[0]\n",
    "    last_close = monthly_df['Close'].iloc[-1]\n",
    "    simple_return = (last_close - first_close) / first_close\n",
    "\n",
    "    # Calculate minutely returns and volatility\n",
    "    minutely_returns = monthly_df['Close'].pct_change().dropna()\n",
    "    monthly_volatility = minutely_returns.std() * np.sqrt(len(minutely_returns))\n",
    "\n",
    "    # Calculate maximum drawdown\n",
    "    cumulative_max = monthly_df['Close'].expanding().max()\n",
    "    drawdowns = (monthly_df['Close'] - cumulative_max) / cumulative_max\n",
    "    max_drawdown = drawdowns.min()\n",
    "\n",
    "    n_trades = monthly_df['N_Trades'].sum()\n",
    "\n",
    "    return {\n",
    "        \"n_sample\": len(monthly_df),\n",
    "        \"n_trade\": n_trades,\n",
    "        \"monthly_return\": simple_return,\n",
    "        \"monthly_volatility\": monthly_volatility,\n",
    "        \"monthly_mdd\": max_drawdown\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_perf = df.rename(columns={\"1m_open_time\": \"Date\", \"1m_close_px\": \"Close\"})\n",
    "df_perf[\"N_Trades\"] = df[\"1m_number_of_trades\"].abs()\n",
    "res = calculate_performance(df_perf, 2022, 1)\n",
    "print(f\"January 2022 BTC Statistics:\")\n",
    "print(f\"N Sample: {res['n_sample']}\")\n",
    "print(f\"N Trade: {res['n_trade']}\")\n",
    "print(f\"Simple Return: {res['monthly_return']:.2%}\")\n",
    "print(f\"Monthly Volatility: {res['monthly_volatility']:.2%}\")\n",
    "print(f\"Maximum Drawdown: {res['monthly_mdd']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the dataframe\n",
    "df_perf = df.rename(columns={\"1m_open_time\": \"Date\", \"1m_close_px\": \"Close\"})\n",
    "df_perf[\"N_Trades\"] = df[\"1m_number_of_trades\"].abs()\n",
    "\n",
    "# Collect statistics\n",
    "year = 2022\n",
    "returns = []\n",
    "vols = []\n",
    "mdds = []\n",
    "annotations = []\n",
    "\n",
    "for month in range(1, 13):\n",
    "    try:\n",
    "        res = calculate_performance(df_perf, year, month)\n",
    "        ret = res['monthly_return']\n",
    "        vol = res['monthly_volatility']\n",
    "        mdd = res['monthly_mdd']\n",
    "\n",
    "        returns.append(ret)\n",
    "        vols.append(vol)\n",
    "        mdds.append(mdd)\n",
    "\n",
    "        annotation = f\"{ret:.2%}\\nσ={vol:.2%}\\nDD={mdd:.2%}\"\n",
    "        annotations.append(annotation)\n",
    "    except Exception as e:\n",
    "        returns.append(np.nan)\n",
    "        annotations.append(\"N/A\")\n",
    "\n",
    "# Convert data into 3x4 shape for heatmap\n",
    "returns_matrix = np.array(returns).reshape(3, 4)\n",
    "annot_matrix = np.array(annotations).reshape(3, 4)\n",
    "\n",
    "# Plot heatmap with annotations\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(\n",
    "    returns_matrix,\n",
    "    annot=annot_matrix,\n",
    "    fmt='',\n",
    "    cmap='RdYlGn',\n",
    "    center=0,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Monthly Return'}\n",
    ")\n",
    "\n",
    "# Label setup\n",
    "plt.title(f\"{year} Monthly BTC Performance Heatmap\")\n",
    "plt.xticks(ticks=np.arange(4)+0.5, labels=[\"Jan–Mar\", \"Apr–Jun\", \"Jul–Sep\", \"Oct–Dec\"])\n",
    "plt.yticks(ticks=np.arange(3)+0.5, labels=[\"Row 1\", \"Row 2\", \"Row 3\"], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare the dataframe\n",
    "df_perf = df.rename(columns={\"1m_open_time\": \"Date\", \"1m_close_px\": \"Close\"})\n",
    "df_perf[\"N_Trades\"] = df[\"1m_number_of_trades\"].abs()\n",
    "\n",
    "# Collect statistics\n",
    "year = 2023\n",
    "returns = []\n",
    "vols = []\n",
    "mdds = []\n",
    "annotations = []\n",
    "\n",
    "for month in range(1, 13):\n",
    "    try:\n",
    "        res = calculate_performance(df_perf, year, month)\n",
    "        ret = res['monthly_return']\n",
    "        vol = res['monthly_volatility']\n",
    "        mdd = res['monthly_mdd']\n",
    "\n",
    "        returns.append(ret)\n",
    "        vols.append(vol)\n",
    "        mdds.append(mdd)\n",
    "\n",
    "        annotation = f\"{ret:.2%}\\nσ={vol:.2%}\\nDD={mdd:.2%}\"\n",
    "        annotations.append(annotation)\n",
    "    except Exception as e:\n",
    "        returns.append(np.nan)\n",
    "        annotations.append(\"N/A\")\n",
    "\n",
    "# Convert data into 3x4 shape for heatmap\n",
    "returns_matrix = np.array(returns).reshape(3, 4)\n",
    "annot_matrix = np.array(annotations).reshape(3, 4)\n",
    "\n",
    "# Plot heatmap with annotations\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(\n",
    "    returns_matrix,\n",
    "    annot=annot_matrix,\n",
    "    fmt='',\n",
    "    cmap='RdYlGn',\n",
    "    center=0,\n",
    "    linewidths=0.5,\n",
    "    cbar_kws={'label': 'Monthly Return'}\n",
    ")\n",
    "\n",
    "# Label setup\n",
    "plt.title(f\"{year} Monthly BTC Performance Heatmap\")\n",
    "plt.xticks(ticks=np.arange(4)+0.5, labels=[\"Jan–Mar\", \"Apr–Jun\", \"Jul–Sep\", \"Oct–Dec\"])\n",
    "plt.yticks(ticks=np.arange(3)+0.5, labels=[\"Row 1\", \"Row 2\", \"Row 3\"], rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the filtered data to avoid SettingWithCopyWarning\n",
    "df_hourly = df[df['is_1h_closed'] == True].copy()\n",
    "\n",
    "# Calculate 30-period moving average using .loc to avoid warning\n",
    "df_hourly.loc[:, '1h_ma_30'] = df_hourly['1h_close_px'].rolling(window=30).mean()\n",
    "df_ma = pd.merge(df, df_hourly[['1m_open_time', '1h_ma_30']], on='1m_open_time', how='left')\n",
    "df_ma_interpolated = df_ma.copy()\n",
    "df_ma_interpolated['1h_ma_30'] = df_ma_interpolated['1h_ma_30'].ffill()\n",
    "df_ma_interpolated.dropna(inplace=True)\n",
    "df_ma_interpolated['1h_ma_30_diff'] = (df_ma_interpolated['1m_close_px'] - df_ma_interpolated['1h_ma_30']) / df_ma_interpolated['1h_ma_30']\n",
    "# df_ma_interpolated['1h_ma_30_diff']\n",
    "# Calculate quantiles\n",
    "q_01 = df_ma_interpolated['1h_ma_30_diff'].quantile(0.01)\n",
    "q_99 = df_ma_interpolated['1h_ma_30_diff'].quantile(0.99)\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_ma_interpolated['1h_ma_30_diff'], bins=100, density=True, alpha=0.7)\n",
    "\n",
    "# Add vertical lines for quantiles\n",
    "plt.axvline(q_01, color='r', linestyle='--', label=f'1% quantile: {q_01:.3f}')\n",
    "plt.axvline(q_99, color='r', linestyle='--', label=f'99% quantile: {q_99:.3f}')\n",
    "\n",
    "plt.title('Distribution of 1-Hour MA 30 Price Differences')\n",
    "plt.xlabel('Price Difference from MA')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# df_hourly['signal_2'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma_interpolated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ma_interpolated['signal_2'] =  df_ma_interpolated['1h_ma_30_diff'] < q_01\n",
    "# df_ma_interpolated['signal_3'] =  df_ma_interpolated['1h_ma_30_diff'] > q_99\n",
    "\n",
    "n = len(df_ma_interpolated)\n",
    "usdt_list = [0] * n\n",
    "btc_list = [0] * n\n",
    "portfolio_list = [0] * n\n",
    "\n",
    "usdt_list[0] = 1000\n",
    "btc_list[0] = 0\n",
    "portfolio_list[0] = 1000\n",
    "hold = 0\n",
    "stop_loss = 0.03\n",
    "\n",
    "n_trade_usdt = 500\n",
    "\n",
    "\n",
    "    \n",
    "df[\"btc_1\"] = btc_list\n",
    "df[\"usdt_1\"] = usdt_list\n",
    "df[\"portfolio_1_open_px\"] = df[\"btc_1\"] * df[\"1m_open_px\"] + df[\"usdt_1\"]\n",
    "df[\"portfolio_1_high_px\"] = df[\"btc_1\"] * df[\"1m_high_px\"] + df[\"usdt_1\"]\n",
    "df[\"portfolio_1_low_px\"] = df[\"btc_1\"] * df[\"1m_low_px\"] + df[\"usdt_1\"]\n",
    "df[\"portfolio_1_close_px\"] = df[\"btc_1\"] * df[\"1m_close_px\"] + df[\"usdt_1\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all previous calculations and start fresh\n",
    "# Implementing Black-Scholes stock price simulation from scratch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set simulation parameters\n",
    "S0 = 100  # Initial stock price\n",
    "mu = 0.1  # Expected annual return (10%)\n",
    "sigma = 0.2  # Annual volatility (20%)\n",
    "T = 1.0  # Time horizon in years\n",
    "N = 252  # Number of trading days\n",
    "dt = T/N  # Time step size\n",
    "\n",
    "# Generate random normal numbers for Brownian motion\n",
    "np.random.seed(42)\n",
    "W = np.random.standard_normal(N)\n",
    "\n",
    "# Initialize arrays\n",
    "t = np.linspace(0, T, N)\n",
    "S = np.zeros(N)\n",
    "\n",
    "# Generate stock price path\n",
    "S[0] = S0\n",
    "for i in range(1, N):\n",
    "    S[i] = S[i-1] * np.exp((mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * W[i-1])\n",
    "\n",
    "# Create timestamps for the simulation\n",
    "base_date = datetime.now()\n",
    "dates = [base_date + timedelta(days=x) for x in range(N)]\n",
    "\n",
    "# Create DataFrame with simulated prices\n",
    "df_simulated = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Price': S,\n",
    "    'Returns': np.log(S[1:]/S[:-1]).tolist() + [0]  # Log returns\n",
    "})\n",
    "\n",
    "# Plot simulated price path\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_simulated['Date'], df_simulated['Price'], label='Simulated Stock Price')\n",
    "plt.title('Black-Scholes Stock Price Simulation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\nSimulation Summary Statistics:\")\n",
    "print(df_simulated['Price'].describe())\n",
    "print(\"\\nDaily Returns Summary Statistics:\")\n",
    "print(df_simulated['Returns'].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simulated[\"SimpleReturn\"] = df_simulated[\"Price\"].pct_change()\n",
    "df_simulated[\"CumulativeReturn\"] = (1 + df_simulated[\"SimpleReturn\"]).cumprod()\n",
    "# df_simulated[\"CumulativeReturn\"].plot()\n",
    "# Plot simulated price path\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_simulated['Date'], df_simulated['CumulativeReturn'], label='Simulated Stock Return')\n",
    "plt.title('Black-Scholes Stock Price Simulation')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
